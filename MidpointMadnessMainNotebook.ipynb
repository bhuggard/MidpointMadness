{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "\n",
    "#NFL pbp data\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "#Basics / visualizations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Machine learning tools\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Stats Stuff\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "\n",
    "#Turn off max columns for pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Turn off when showing off, switch comments to change\n",
    "pd.options.mode.chained_assignment = None  # Disable the warning\n",
    "# pd.options.mode.chained_assignment = 'warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Prepping Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules_df = nfl.import_schedules([2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_implied_totals(df):\n",
    "    \"\"\"\n",
    "    Calculate the implied home and away team totals based on the spread and total lines.\n",
    "    \"\"\"\n",
    "    #Implied totals based on the total and spread lines\n",
    "    df['implied_home_total'] = (df['total_line'] + df['spread_line']) / 2\n",
    "    df['implied_away_total'] = (df['total_line'] - df['spread_line']) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules_df = calculate_implied_totals(schedules_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules_df.drop(columns= ['away_coach', 'home_coach', 'referee',\n",
    "       'stadium_id', 'stadium', 'away_score', 'home_score',\n",
    "       'location', 'result', 'total', 'overtime', 'old_game_id', 'gsis',\n",
    "       'nfl_detail_id', 'pfr', 'pff', 'espn', 'ftn', 'away_rest', 'home_rest',\n",
    "       'away_moneyline', 'home_moneyline', 'spread_line', 'away_spread_odds',\n",
    "       'home_spread_odds', 'total_line', 'under_odds', 'over_odds', 'div_game', 'away_qb_id', 'home_qb_id', 'gameday', 'weekday',\n",
    "       'gametime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame for away quarterbacks\n",
    "away_df = schedules_df[['game_id', 'season', 'game_type', 'week', 'away_team', 'home_team', 'away_qb_name', 'implied_away_total', 'roof', 'surface',]].copy()\n",
    "away_df.rename(columns={'away_qb_name': 'qb_name', 'implied_away_total': 'implied_total'}, inplace=True)\n",
    "away_df['home_away'] = 'away'\n",
    "away_df['posteam'] = away_df['away_team']\n",
    "away_df['defteam'] = away_df['home_team']\n",
    "\n",
    "#Create a DataFrame for home quarterbacks\n",
    "home_df = schedules_df[['game_id', 'season', 'game_type', 'week', 'away_team', 'home_team', 'home_qb_name', 'implied_home_total', 'roof', 'surface']].copy()\n",
    "home_df.rename(columns={'home_qb_name': 'qb_name', 'implied_home_total': 'implied_total'}, inplace=True)\n",
    "home_df['home_away'] = 'home'\n",
    "home_df['posteam'] = home_df['home_team']\n",
    "home_df['defteam'] = home_df['away_team']\n",
    "\n",
    "#Concatenate both DataFrames\n",
    "combined_schedule_df = pd.concat([away_df, home_df])\n",
    "\n",
    "#Reset index for cleanliness\n",
    "combined_schedule_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_passer_name(qb_name):\n",
    "    if pd.isna(qb_name):  #Check if the name is NaN\n",
    "        return \"\"\n",
    "    \n",
    "    name_parts = qb_name.split()\n",
    "    \n",
    "    #Extract the first name and last name\n",
    "    first_name = name_parts[0]\n",
    "    last_name = name_parts[-1]  # Last name should always be the last part\n",
    "    \n",
    "    return f\"{first_name[0]}.{last_name}\"\n",
    "\n",
    "#Apply the function to create the new 'player_passer_name' column\n",
    "combined_schedule_df['passer_player_name'] = combined_schedule_df['qb_name'].apply(format_passer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder Columns\n",
    "combined_schedule_df = combined_schedule_df[['game_id', 'season', 'game_type', 'week', 'roof', 'surface',\n",
    "                                             'posteam', 'defteam', 'home_team', 'away_team', 'qb_name', 'passer_player_name', 'implied_total', 'home_away']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing PBP Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 done.\n",
      "2015 done.\n",
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2023 done.\n",
      "2024 done.\n",
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "#Select only the relevant columns\n",
    "columns = ['game_id', 'passer_player_name', 'posteam', 'defteam', 'season', 'week', 'home_team', 'away_team', 'play_type', 'air_yards', \n",
    "           'yards_after_catch', 'epa', 'complete_pass', 'incomplete_pass', 'interception', 'qb_hit', 'sack', 'pass_touchdown',\n",
    "           'passing_yards', 'cpoe', 'roof', 'surface']\n",
    "\n",
    "#Loading in the NFL pbp data\n",
    "data = nfl.import_pbp_data(range(2014,2024 + 1), columns, include_participation=False)\n",
    "\n",
    "#nfl-data-py still loads other columns, so we again need to set our data equal to only the columns we want\n",
    "data = data[columns]\n",
    "\n",
    "#Drop all rows that are not a pass\n",
    "data = data[data['play_type'] == 'pass']\n",
    "\n",
    "#Drop the play type column\n",
    "passer_data = data.drop(columns=['play_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passer DF Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data together by passer, week, season and aggregate\n",
    "passer_df = passer_data.groupby(['game_id', 'passer_player_name', 'week', 'season'], as_index=False).agg(\n",
    "    {'posteam' : 'first',\n",
    "     'defteam' : 'first',\n",
    "     'home_team' : 'first',\n",
    "     'away_team' : 'first',\n",
    "     'air_yards' : 'sum',\n",
    "     'yards_after_catch' : 'sum',\n",
    "     'epa' : 'sum',\n",
    "     'complete_pass' : 'sum',\n",
    "     'incomplete_pass' : 'sum',\n",
    "     'interception' : 'sum',\n",
    "     'qb_hit' : 'sum',\n",
    "     'sack' : 'sum',\n",
    "     'pass_touchdown' : 'sum',\n",
    "     'passing_yards' : 'sum',\n",
    "     'cpoe' : 'mean',\n",
    "     'roof' : 'first',\n",
    "     'surface' : 'first'\n",
    "     }\n",
    ")\n",
    "\n",
    "#Create a new column that is completion percentage\n",
    "passer_df['completion_percentage'] = passer_df['complete_pass'] / (passer_df['complete_pass'] + passer_df['incomplete_pass'])\n",
    "\n",
    "#Create a new column that is the number of pass attempts\n",
    "passer_df['pass_attempts'] = passer_df['complete_pass'] + passer_df['incomplete_pass']\n",
    "\n",
    "#Create a new column that equals 1 if the passer is the home team and 0 if the passer is the away team\n",
    "passer_df['home_flag'] = passer_df['home_team'] == passer_df['posteam']\n",
    "\n",
    "#Reorder the columns\n",
    "passer_df = passer_df[['home_team', 'away_team', 'complete_pass', 'incomplete_pass' ,'game_id', 'passer_player_name', 'posteam', 'defteam', 'season', 'week', 'passing_yards', 'home_flag', 'completion_percentage', 'pass_attempts',\n",
    "                       'air_yards',  'yards_after_catch', 'epa', 'interception', 'qb_hit', 'sack', 'pass_touchdown', \n",
    "                        'cpoe', 'roof', 'surface']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense DF Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the relevant columns\n",
    "defense_columns = ['defteam', 'season', 'week', 'home_team', 'away_team', 'play_type', 'air_yards',\n",
    "                   'yards_after_catch', 'epa', 'complete_pass', 'incomplete_pass', 'interception', 'qb_hit', 'sack', 'pass_touchdown',\n",
    "                   'passing_yards', 'cpoe', 'roof', 'surface']\n",
    "\n",
    "\n",
    "#nfl-data-py still loads other columns, so we again need to set our data equal to only the columns we want\n",
    "defense_data = data[defense_columns]\n",
    "\n",
    "#Drop the play type column\n",
    "defense_data = defense_data.drop(columns=['play_type'])\n",
    "\n",
    "#Group the data together by passer, week, season and aggregate\n",
    "defense_df = defense_data.groupby(['defteam', 'week', 'season'], as_index=False).agg(\n",
    "    {'home_team': 'first',\n",
    "     'away_team': 'first',\n",
    "     'air_yards': 'sum',\n",
    "     'yards_after_catch': 'sum',\n",
    "     'epa': 'sum',\n",
    "     'complete_pass': 'sum',\n",
    "     'incomplete_pass': 'sum',\n",
    "     'interception': 'sum',\n",
    "     'qb_hit': 'sum',\n",
    "     'sack': 'sum',\n",
    "     'pass_touchdown': 'sum',\n",
    "     'passing_yards': 'sum',\n",
    "     'cpoe': 'mean',\n",
    "     'roof': 'first',\n",
    "     'surface': 'first'\n",
    "     }\n",
    ")\n",
    "\n",
    "#Create a new column that is completion percentage\n",
    "defense_df['completion_percentage'] = defense_df['complete_pass'] / (defense_df['complete_pass'] + defense_df['incomplete_pass'])\n",
    "\n",
    "#Create a new column that is the number of pass attempts\n",
    "defense_df['pass_attempts'] = defense_df['complete_pass'] + defense_df['incomplete_pass']\n",
    "\n",
    "#Create a new column that equals 1 if the defense is the home team and 0 if the defense is the away team\n",
    "defense_df['home_flag'] = defense_df['home_team'] == defense_df['defteam']\n",
    "\n",
    "#Reorder the columns\n",
    "defense_df = defense_df[['home_team', 'away_team', 'complete_pass', 'incomplete_pass', 'defteam', 'season', 'week', 'home_flag', 'passing_yards', 'completion_percentage', 'pass_attempts',\n",
    "                       'air_yards',  'yards_after_catch', 'epa', 'interception', 'qb_hit', 'sack', 'pass_touchdown', \n",
    "                       'cpoe', 'roof', 'surface']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing, namely exponentially weighted moving averages for offensive and defensive stats to be used as features in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_offensive_ewma(passer_df):\n",
    "    \"\"\"\n",
    "    Calculates EWMA for offensive columns using previous weeks' data, ensuring no leakage by excluding the current week.\n",
    "    Takes into account multiple seasons.\n",
    "    \"\"\"\n",
    "    #Sort by passer, season, and week\n",
    "    passer_df = passer_df.sort_values(by=['passer_player_name', 'season', 'week'])\n",
    "\n",
    "    #Calculate the exponentially weighted moving average for each offensive feature, excluding the current week\n",
    "    passer_df['completion_percentage_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['completion_percentage']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['pass_attempts_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['pass_attempts']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['air_yards_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['air_yards']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['yards_after_catch_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['yards_after_catch']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['epa_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['epa']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['interception_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['interception']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['qb_hit_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['qb_hit']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['sack_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['sack']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['pass_touchdown_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['pass_touchdown']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['passing_yards_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['passing_yards']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['cpoe_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['cpoe']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    return passer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_cleaner(passer_df):\n",
    "    \"\"\"\n",
    "    Preps passer df for merging; drops unnecessary columns\n",
    "    \"\"\"\n",
    "    passer_df.drop(columns=['home_team', 'away_team', 'complete_pass', 'incomplete_pass', 'completion_percentage', 'air_yards', 'yards_after_catch', 'epa', \n",
    "                                    'interception', 'qb_hit', 'sack', 'pass_touchdown', 'cpoe', 'home_team', 'away_team', \n",
    "                                    'complete_pass', 'incomplete_pass'], inplace=True)\n",
    "    \n",
    "    return passer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "passer_emwa = calculate_offensive_ewma(passer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "passer_prepped = pass_cleaner(passer_emwa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_defensive_ewma(defense_df):\n",
    "    \"\"\"\n",
    "    Calculates EWMA for defensive columns using previous weeks' data (excluding the current week).\n",
    "    \"\"\"\n",
    "    #Sort by 'defteam', 'season', and 'week' in ascending order (to ensure time order)\n",
    "    defense_df = defense_df.sort_values(by=['defteam', 'season', 'week'])\n",
    "\n",
    "    #Ensure proper grouping by both defteam and season\n",
    "    defense_df['completion_percentage_ewma'] = defense_df.groupby(['defteam', 'season'])['completion_percentage']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "    \n",
    "    defense_df['pass_attempts_ewma'] = defense_df.groupby(['defteam', 'season'])['pass_attempts']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['air_yards_ewma'] = defense_df.groupby(['defteam', 'season'])['air_yards']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['yards_after_catch_ewma'] = defense_df.groupby(['defteam', 'season'])['yards_after_catch']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['epa_ewma'] = defense_df.groupby(['defteam', 'season'])['epa']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['interception_ewma'] = defense_df.groupby(['defteam', 'season'])['interception']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['qb_hit_ewma'] = defense_df.groupby(['defteam', 'season'])['qb_hit']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['sack_ewma'] = defense_df.groupby(['defteam', 'season'])['sack']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['pass_touchdown_ewma'] = defense_df.groupby(['defteam', 'season'])['pass_touchdown']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['passing_yards_ewma'] = defense_df.groupby(['defteam', 'season'])['passing_yards']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['cpoe_ewma'] = defense_df.groupby(['defteam', 'season'])['cpoe']\\\n",
    "        .transform(lambda x: x.shift().ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    return defense_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cleaner(defense_df):\n",
    "    \"\"\"\n",
    "    Preps passer df for merging; drops unnecessary columns\n",
    "    \"\"\"\n",
    "    #Drop the non-ewma columns\n",
    "    defense_df.drop(columns=['passing_yards','completion_percentage',\n",
    "                            'air_yards', 'yards_after_catch', 'epa',     \n",
    "                            'interception', 'qb_hit', 'sack', 'pass_touchdown', 'pass_attempts', 'cpoe', 'complete_pass', 'incomplete_pass',\n",
    "                            'home_team', 'away_team'\n",
    "                            ], inplace=True)\n",
    "    \n",
    "    return defense_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_ewma = calculate_defensive_ewma(defense_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_prepped = def_cleaner(defense_ewma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the defense and passer dataframes together\n",
    "full_with_ewma = passer_prepped.merge(defense_prepped, how='inner', on=['defteam', 'season', 'week', 'roof', 'surface'], suffixes=('_passer', '_defense'))\n",
    "\n",
    "#Get rid of flukey rows\n",
    "filtered_with_ewma = full_with_ewma[(full_with_ewma['pass_attempts'] > 8) & (full_with_ewma['passing_yards'] >= 10)]\n",
    "\n",
    "#Ford Field is empty, you hate to see that\n",
    "filtered_with_ewma['surface'].replace('', 'fieldturf', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 is NaN's (duh, we use past weeks for EWMA's) for MVP I'll just get rid but for future seasons/rookies I do need a strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_with_ewma = filtered_with_ewma.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the merge based on game_id, season, week, and team\n",
    "filtered_with_ewma_it = pd.merge(filtered_with_ewma, combined_schedule_df[['game_id', 'season', 'week', 'posteam', 'implied_total']], \n",
    "                     on=['game_id', 'season', 'week', 'posteam'], \n",
    "                     how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the target and features\n",
    "target = 'passing_yards'\n",
    "features = filtered_with_ewma_it.columns.drop(['pass_attempts', 'passer_player_name', 'passing_yards', 'posteam', 'defteam', 'season', 'week', 'game_id', 'implied_total'])\n",
    "\n",
    "#Define categorical and numeric columns\n",
    "categorical_columns = ['roof', 'surface', 'home_flag_passer', 'home_flag_defense']\n",
    "numeric_columns = [col for col in features if col not in categorical_columns]\n",
    "\n",
    "#Split the data into training (up to 2023) and testing (2024)\n",
    "train_data = filtered_with_ewma_it[filtered_with_ewma_it['season'] <= 2023]\n",
    "test_data = filtered_with_ewma_it[filtered_with_ewma_it['season'] == 2024]\n",
    "\n",
    "#Separate features and target for both training and testing\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "#Create a ColumnTransformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_columns),\n",
    "        ('num', StandardScaler(), numeric_columns)\n",
    "    ])\n",
    "\n",
    "#Apply the transformations to the training and test sets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic RMSE on the 2024 season: 75.5245132446289\n",
      "RMSE on the 2024 season without the min and max true passing yard games: 72.85186004638672\n"
     ]
    }
   ],
   "source": [
    "#Initialize the basic XGBoost model\n",
    "xgb_model_basic = xgb.XGBRegressor(\n",
    "    n_estimators=142,  # Basic number of boosting rounds\n",
    "    learning_rate=0.101,  # Standard learning rate\n",
    "    max_depth=3,        # Typical depth for a basic model\n",
    "    reg_lambda= 2,      #something something regularization\n",
    "    random_state=42,    # For reproducibility\n",
    "    n_jobs=-1           # Use all CPU cores for faster training\n",
    ")\n",
    "\n",
    "#Train the model on the entire pre-2024 data\n",
    "xgb_model_basic.fit(X_train_transformed, y_train)\n",
    "\n",
    "#Make predictions on the 2024 season (X_test)\n",
    "y_pred = xgb_model_basic.predict(X_test_transformed)\n",
    "\n",
    "#Calculate RMSE for the 2024 season predictions\n",
    "rmse_basic = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Basic RMSE on the 2024 season: {rmse_basic}\")\n",
    "\n",
    "#Attach predictions back to the original test DataFrame\n",
    "test_data['predicted_passing_yards'] = y_pred\n",
    "\n",
    "#Remove the rows with the largest and smallest passing yards\n",
    "max_passing_yards = test_data['passing_yards'].max()\n",
    "min_passing_yards = test_data['passing_yards'].min()\n",
    "\n",
    "#Filter the test_data to exclude the rows with max and min passing yards\n",
    "filtered_test_data = test_data[(test_data['passing_yards'] != max_passing_yards) & (test_data['passing_yards'] != min_passing_yards)]\n",
    "\n",
    "#Calculate RMSE for the remaining data\n",
    "rmse_filtered = mean_squared_error(filtered_test_data['passing_yards'], filtered_test_data['predicted_passing_yards'], squared=False)\n",
    "print(f\"RMSE on the 2024 season without the min and max true passing yard games: {rmse_filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ^ this error score sucks (bad!) best is around 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure test_data is just the 2024 season\n",
    "test_data = filtered_with_ewma_it[filtered_with_ewma_it['season'] == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach predictions back to the original test DataFrame\n",
    "test_data['predicted_passing_yards'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate whether the model over-predicted or under-predicted to visualize trends in predictions across weeks\n",
    "test_data['pyoe'] = test_data['passing_yards'] - test_data['predicted_passing_yards']\n",
    "\n",
    "#To be used in monte carlo simulator\n",
    "global_residual_std = test_data['pyoe'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-62.63853, 58.73861)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_negative = test_data[test_data['pyoe'] < 0]['pyoe'].mean()\n",
    "average_positive = test_data[test_data['pyoe'] > 0]['pyoe'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Week Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewma_tester_off(passer_df):\n",
    "    \"\"\"\n",
    "    Calculates EWMA for offensive columns using the current and previous weeks' data, including the current week.\n",
    "    Takes into account multiple seasons.\n",
    "    \"\"\"\n",
    "    #Sort by passer, season, and week\n",
    "    passer_df = passer_df.sort_values(by=['passer_player_name', 'season', 'week'])\n",
    "\n",
    "    #Calculate the exponentially weighted moving average for each offensive feature, including the current week\n",
    "    passer_df['completion_percentage_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['completion_percentage']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['pass_attempts_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['pass_attempts']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['air_yards_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['air_yards']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['yards_after_catch_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['yards_after_catch']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['epa_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['epa']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['interception_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['interception']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['qb_hit_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['qb_hit']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['sack_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['sack']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['pass_touchdown_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['pass_touchdown']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['passing_yards_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['passing_yards']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    passer_df['cpoe_ewma'] = passer_df.groupby(['passer_player_name', 'season'])['cpoe']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    return passer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "passer_df_tester = passer_df[(passer_df['season'] == 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_passer_nc = calculate_ewma_tester_off(passer_df_tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_passer = pass_cleaner(prediction_set_passer_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of flukey rows and get current week offensive stuff ready to join on a prepped schedules DF\n",
    "prediction_set_passer_recents = prediction_set_passer[(prediction_set_passer['pass_attempts'] > 8) & (prediction_set_passer['passing_yards'] >= 10)]\n",
    "\n",
    "prediction_set_passer_recents = prediction_set_passer_recents.loc[prediction_set_passer_recents.groupby('posteam')['week'].idxmax()]\n",
    "\n",
    "prediction_set_passer_recents['surface'].replace('', 'fieldturf', inplace=True)\n",
    "\n",
    "prediction_set_passer_recents.drop(columns=['game_id', 'passer_player_name', 'defteam', 'roof', 'surface', 'home_flag', 'passing_yards', 'pass_attempts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewma_tester_def(defense_df):\n",
    "    \"\"\"\n",
    "    Calculates EWMA for defensive columns using previous weeks' data (excluding the current week).\n",
    "    \"\"\"\n",
    "    #Sort by 'defteam', 'season', and 'week' in ascending order (to ensure time order)\n",
    "    defense_df = defense_df.sort_values(by=['defteam', 'season', 'week'])\n",
    "\n",
    "    #Ensure proper grouping by both defteam and season\n",
    "    defense_df['completion_percentage_ewma'] = defense_df.groupby(['defteam', 'season'])['completion_percentage']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "    \n",
    "    defense_df['pass_attempts_ewma'] = defense_df.groupby(['defteam', 'season'])['pass_attempts']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['air_yards_ewma'] = defense_df.groupby(['defteam', 'season'])['air_yards']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['yards_after_catch_ewma'] = defense_df.groupby(['defteam', 'season'])['yards_after_catch']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['epa_ewma'] = defense_df.groupby(['defteam', 'season'])['epa']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['interception_ewma'] = defense_df.groupby(['defteam', 'season'])['interception']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['qb_hit_ewma'] = defense_df.groupby(['defteam', 'season'])['qb_hit']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['sack_ewma'] = defense_df.groupby(['defteam', 'season'])['sack']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['pass_touchdown_ewma'] = defense_df.groupby(['defteam', 'season'])['pass_touchdown']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['passing_yards_ewma'] = defense_df.groupby(['defteam', 'season'])['passing_yards']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    defense_df['cpoe_ewma'] = defense_df.groupby(['defteam', 'season'])['cpoe']\\\n",
    "        .transform(lambda x: x.ewm(min_periods=1, span=5).mean())\n",
    "\n",
    "    return defense_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_df_tester = defense_df[defense_df['season'] == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_defense_nc = calculate_ewma_tester_def(defense_df_tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_defense = def_cleaner(prediction_set_defense_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_defense_recents = prediction_set_defense.loc[prediction_set_defense.groupby('defteam')['week'].idxmax()]\n",
    "\n",
    "prediction_set_defense_recents['surface'].replace('', 'fieldturf', inplace=True)\n",
    "\n",
    "prediction_set_defense_recents.drop(columns=['roof', 'surface', 'home_flag'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_week_to_next(df):\n",
    "    \"\"\"\n",
    "    Function to update all teams to the next NFL week based on the current max week.\n",
    "    Teams that are behind the max week will jump to the next NFL week.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing NFL data including the 'week' column.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'week' values updated appropriately.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    #Current week\n",
    "    current_week = df_copy['week'].max()\n",
    "\n",
    "    #Increment all weeks to the next NFL week (based on current max week)\n",
    "    df_copy['week'] = df_copy['week'].apply(lambda x: current_week + 1)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_week_offense_set = update_week_to_next(prediction_set_passer_recents)\n",
    "current_week_defense_set = update_week_to_next(prediction_set_defense_recents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_week_defense_set.rename(columns={\n",
    "    'completion_percentage_ewma': 'completion_percentage_ewma_defense',\n",
    "    'pass_attempts_ewma': 'pass_attempts_ewma_defense',\n",
    "    'air_yards_ewma': 'air_yards_ewma_defense',\n",
    "    'yards_after_catch_ewma': 'yards_after_catch_ewma_defense',\n",
    "    'epa_ewma': 'epa_ewma_defense',\n",
    "    'interception_ewma': 'interception_ewma_defense',\n",
    "    'qb_hit_ewma': 'qb_hit_ewma_defense',\n",
    "    'sack_ewma': 'sack_ewma_defense',\n",
    "    'pass_touchdown_ewma': 'pass_touchdown_ewma_defense',\n",
    "    'passing_yards_ewma': 'passing_yards_ewma_defense',\n",
    "    'cpoe_ewma': 'cpoe_ewma_defense'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_week_offense_set.rename(columns={\n",
    "    'completion_percentage_ewma': 'completion_percentage_ewma_passer',\n",
    "    'pass_attempts_ewma': 'pass_attempts_ewma_passer',\n",
    "    'air_yards_ewma': 'air_yards_ewma_passer',\n",
    "    'yards_after_catch_ewma': 'yards_after_catch_ewma_passer',\n",
    "    'epa_ewma': 'epa_ewma_passer',\n",
    "    'interception_ewma': 'interception_ewma_passer',\n",
    "    'qb_hit_ewma': 'qb_hit_ewma_passer',\n",
    "    'sack_ewma': 'sack_ewma_passer',\n",
    "    'pass_touchdown_ewma': 'pass_touchdown_ewma_passer',\n",
    "    'passing_yards_ewma': 'passing_yards_ewma_passer',\n",
    "    'cpoe_ewma': 'cpoe_ewma_passer'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_schedule_preds = combined_schedule_df[combined_schedule_df['season'] == combined_schedule_df['season'].max()]\n",
    "combined_schedule_preds.drop(columns=['home_away'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First merge stitching features\n",
    "off_plus_schedule = pd.merge(\n",
    "    current_week_offense_set, \n",
    "    combined_schedule_preds, \n",
    "    on=['season', 'week', 'posteam'], \n",
    "    suffixes=('_fromoff', '_fromschedule'), \n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here comes the defensive stuff\n",
    "full_pred_features = pd.merge(\n",
    "    off_plus_schedule,\n",
    "    current_week_defense_set,\n",
    "    on=['season', 'week', 'defteam'],  #Merging on these columns\n",
    "    suffixes=('_fromscheduleAHHHHHH', '_DEFENSEHUGSYDEFENSEHUGSY'), #this should make it obvious if there's an error\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of the new column order\n",
    "new_column_order = ['game_id', 'season', 'week','game_type','posteam', 'defteam', 'home_team', 'away_team', 'qb_name', 'passer_player_name', \n",
    "              'implied_total', 'roof', 'surface',\n",
    "              'completion_percentage_ewma_passer', 'pass_attempts_ewma_passer',\n",
    "              'air_yards_ewma_passer', 'yards_after_catch_ewma_passer',\n",
    "              'epa_ewma_passer', 'interception_ewma_passer', 'qb_hit_ewma_passer',\n",
    "              'sack_ewma_passer', 'pass_touchdown_ewma_passer',\n",
    "              'passing_yards_ewma_passer', 'cpoe_ewma_passer', 'completion_percentage_ewma_defense',\n",
    "              'pass_attempts_ewma_defense', 'air_yards_ewma_defense',\n",
    "              'yards_after_catch_ewma_defense', 'epa_ewma_defense',\n",
    "              'interception_ewma_defense', 'qb_hit_ewma_defense', 'sack_ewma_defense',\n",
    "              'pass_touchdown_ewma_defense', 'passing_yards_ewma_defense',\n",
    "              'cpoe_ewma_defense']\n",
    "\n",
    "#Reorder inplace\n",
    "full_pred_features = full_pred_features[new_column_order]\n",
    "\n",
    "#Create the home_flag_passer column\n",
    "full_pred_features['home_flag_passer'] = full_pred_features['posteam'] == full_pred_features['home_team']\n",
    "\n",
    "#Create the home_flag_defense column\n",
    "full_pred_features['home_flag_defense'] = full_pred_features['defteam'] == full_pred_features['home_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_passing_yards(df, model, preprocessor, features, categorical_columns, numeric_columns, target_column='predicted_passing_yards'):\n",
    "    \"\"\"\n",
    "    Function to make passing yard predictions on a new dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    new_data (pd.DataFrame): The new dataframe containing feature columns.\n",
    "    model (xgb.XGBRegressor): Trained XGBoost model.\n",
    "    preprocessor (ColumnTransformer): Preprocessor object for transforming the features.\n",
    "    features (list): List of feature columns used by the model.\n",
    "    categorical_columns (list): List of categorical columns to be preprocessed.\n",
    "    numeric_columns (list): List of numeric columns to be preprocessed.\n",
    "    target_column (str): The name of the column for storing the predictions. Default is 'predicted_passing_yards'.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The input dataframe with an added column of predicted passing yards.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Select and transform the features from the new data\n",
    "    X_new = df[features]\n",
    "    \n",
    "    #Apply preprocessing (scaling and encoding)\n",
    "    X_new_transformed = preprocessor.transform(X_new)\n",
    "    \n",
    "    #Make predictions using the trained model\n",
    "    df[target_column] = model.predict(X_new_transformed)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Example usage\n",
    "upcoming_week_predictions = predict_passing_yards(full_pred_features, xgb_model_basic, preprocessor, features, categorical_columns, numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get o/u's\n",
    "\n",
    "upcoming_week_predictions['pass_yards_ou'] = upcoming_week_predictions['predicted_passing_yards'].apply(lambda x: round(x * 2) / 2)\n",
    "\n",
    "clean_predictions = upcoming_week_predictions[['game_id', 'season', 'week', 'game_type', 'posteam', 'defteam',\n",
    "       'home_team', 'away_team', 'qb_name', 'predicted_passing_yards', 'pass_yards_ou',\n",
    "       'implied_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'posteam' and aggregate 'pyoe' values into a list\n",
    "pyoe_list = test_data.groupby('posteam')['pyoe'].apply(list).reset_index()\n",
    "\n",
    "# Rename the 'pyoe' column to 'pyoe_list' to reflect that it now contains lists of values\n",
    "pyoe_list.rename(columns={'pyoe': 'pyoe_list'}, inplace=True)\n",
    "\n",
    "# Sort by the length of the list or by other criteria if needed (e.g., by the number of games played)\n",
    "pyoe_list.sort_values(by='posteam', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_predictions = pd.merge(pyoe_list, clean_predictions, on='posteam', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_predictions = clean_predictions[['game_id', 'season', 'week', 'game_type', 'implied_total', 'posteam', 'defteam',\n",
    "       'home_team', 'away_team', 'qb_name', 'predicted_passing_yards', 'pass_yards_ou', 'pyoe_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "def monte_carlo_simulations_truncated(df, global_residual_std, residual_col='pyoe_list',\n",
    "                                      predicted_col='predicted_passing_yards', num_simulations=1000,\n",
    "                                      noise_scale=0.25, min_yards=50, max_yards=650):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation for all QBs using truncated normal distribution to ensure realistic passing yard values.\n",
    "    :param df: DataFrame containing QBs with predicted means and mean team residuals\n",
    "    :param global_residual_std: Global residual standard deviation to use for the distribution\n",
    "    :param residual_col: Column containing team-specific mean residuals\n",
    "    :param predicted_col: Column containing predicted passing yards for each QB\n",
    "    :param num_simulations: Number of Monte Carlo simulations to run per QB\n",
    "    :param noise_scale: Standard deviation of the added noise\n",
    "    :param min_yards: Minimum passing yards to ensure no unrealistic low values\n",
    "    :param max_yards: Maximum passing yards to cap extreme outliers\n",
    "    :return: Dictionary of QBs with their simulated passing yard distributions\n",
    "    \"\"\"\n",
    "    qb_simulations = {}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        qb_name = row['qb_name']\n",
    "        predicted_mean = row[predicted_col]\n",
    "        mean_team_residual = row[residual_col]\n",
    "\n",
    "        # Calculate the truncated normal distribution parameters\n",
    "        lower_bound = (min_yards - predicted_mean) / global_residual_std\n",
    "        upper_bound = (max_yards - predicted_mean) / global_residual_std\n",
    "\n",
    "        # Sample from the truncated normal distribution\n",
    "        truncated_simulations = truncnorm.rvs(lower_bound, upper_bound, loc=predicted_mean, scale=global_residual_std, size=num_simulations)\n",
    "\n",
    "        # Add a small amount of noise to introduce variability\n",
    "        noise = np.random.normal(loc=0, scale=noise_scale, size=num_simulations)\n",
    "        simulations = truncated_simulations + noise\n",
    "\n",
    "        # Ensure no negative values by applying the minimum passing yard threshold\n",
    "        simulations = np.maximum(min_yards, simulations)\n",
    "\n",
    "        # Save the simulations for this QB\n",
    "        qb_simulations[qb_name] = simulations\n",
    "\n",
    "    return qb_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_simulations = monte_carlo_simulations_truncated(clean_predictions, global_residual_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_odds_to_american(implied_prob):\n",
    "    \"\"\"\n",
    "    Convert implied probability to American odds format.\n",
    "    :param implied_prob: Implied probability (between 0 and 1)\n",
    "    :return: American odds (with + for positive odds)\n",
    "    \"\"\"\n",
    "    if implied_prob == 0:\n",
    "        return 'N/A'\n",
    "    if implied_prob >= 0.5:\n",
    "        american_odds = -100 / implied_prob\n",
    "    else:\n",
    "        american_odds = (1 / implied_prob - 1) * 100\n",
    "    \n",
    "    # If positive odds, add the \"+\" sign in front\n",
    "    if american_odds > 0:\n",
    "        return f\"+{round(american_odds)}\"\n",
    "    else:\n",
    "        return round(american_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint_madness(qb_name, qb_simulations, over_qbs=[], under_qbs=[]):\n",
    "    \"\"\"\n",
    "    Function to simulate over/under passing yard predictions in Midpoint Madness game.\n",
    "    \n",
    "    :param qb_name: The name of the main QB to start with.\n",
    "    :param qb_simulations: Dictionary containing simulated passing yard results for all QBs.\n",
    "    :param over_qbs: List of QB names that the user thinks will pass for fewer yards than the main QB.\n",
    "    :param under_qbs: List of QB names that the user thinks will pass for more yards than the main QB.\n",
    "    \n",
    "    :return: Dictionary of probabilities or betting odds for each over/under comparison.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    combined_prob = 1  # To calculate the combined probability\n",
    "\n",
    "    # Simulations for the chosen QB\n",
    "    main_qb_simulations = qb_simulations[qb_name]\n",
    "    \n",
    "    # Calculate probabilities for 'over' comparisons\n",
    "    for over_qb in over_qbs:\n",
    "        over_qb_simulations = qb_simulations[over_qb]\n",
    "        prob_main_qb_more = np.mean(main_qb_simulations > over_qb_simulations)\n",
    "        results[f\"{qb_name} > {over_qb}\"] = {\n",
    "            'probability': prob_main_qb_more,\n",
    "            'american_odds': implied_odds_to_american(prob_main_qb_more)\n",
    "        }\n",
    "        # Update the combined probability\n",
    "        combined_prob *= prob_main_qb_more\n",
    "    \n",
    "    # Calculate probabilities for 'under' comparisons\n",
    "    for under_qb in under_qbs:\n",
    "        under_qb_simulations = qb_simulations[under_qb]\n",
    "        prob_main_qb_less = np.mean(main_qb_simulations < under_qb_simulations)\n",
    "        results[f\"{qb_name} < {under_qb}\"] = {\n",
    "            'probability': prob_main_qb_less,\n",
    "            'american_odds': implied_odds_to_american(prob_main_qb_less)\n",
    "        }\n",
    "        # Update the combined probability\n",
    "        combined_prob *= prob_main_qb_less\n",
    "    \n",
    "    # Add combined probability to the results\n",
    "    results['combined_probability'] = combined_prob\n",
    "    results['combined_american_odds'] = implied_odds_to_american(combined_prob)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kyler Murray > Bryce Young: Probability = 0.63, American Odds = -160\n",
      "Kyler Murray > Lamar Jackson: Probability = 0.32, American Odds = +214\n",
      "Kyler Murray < Josh Allen: Probability = 0.64, American Odds = -155\n",
      "Kyler Murray < Jared Goff: Probability = 0.73, American Odds = -137\n",
      "combined_probability: 0.09\n",
      "combined_american_odds: +969\n"
     ]
    }
   ],
   "source": [
    "# Run the Midpoint Madness function for Kyler Murray\n",
    "results = midpoint_madness(\n",
    "    qb_name='Kyler Murray',\n",
    "    qb_simulations=qb_simulations,\n",
    "    over_qbs=['Bryce Young', 'Lamar Jackson'],  # QBs you think Kyler will pass more than\n",
    "    under_qbs=['Josh Allen', 'Jared Goff']  # QBs you think Kyler will pass fewer than\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for comparison, data in results.items():\n",
    "    if comparison == 'combined_probability':\n",
    "        # For combined probability (which is a float), format as a number\n",
    "        print(f\"{comparison}: {data:.2f}\")\n",
    "    elif comparison == 'combined_american_odds':\n",
    "        # Print combined American odds directly since it's a string\n",
    "        print(f\"{comparison}: {data}\")\n",
    "    else:\n",
    "        # For comparison results, format probability and print American odds as a string\n",
    "        print(f\"{comparison}: Probability = {data['probability']:.2f}, American Odds = {data['american_odds']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charts for model stuff if I need to look. It's a pretty shit model. It does ok I guess but not a lot of variance in projection lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity checker\n",
    "\n",
    "# min_max_results = {}\n",
    "# for qb_name, simulations in qb_simulations.items():\n",
    "#     min_max_results[qb_name] = {\n",
    "#         'min_passing_yards': np.min(simulations),\n",
    "#         'max_passing_yards': np.max(simulations)\n",
    "#     }\n",
    "\n",
    "# # Convert the min and max passing yards results into a DataFrame\n",
    "# min_max_df = pd.DataFrame.from_dict(min_max_results, orient='index').reset_index()\n",
    "# min_max_df.rename(columns={'index': 'qb_name'}, inplace=True)\n",
    "\n",
    "# min_max_df.sort_values(by='min_passing_yards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the histogram of PYOE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(test_data['pyoe'], bins=25, edgecolor='black', alpha=0.7)\n",
    "# plt.title('Distribution of Pass Yards Over Expected (PYOE)', fontsize=16)\n",
    "# plt.xlabel('PYOE (Predicted Passing Yards - Actual Passing Yards)', fontsize=12)\n",
    "# plt.ylabel('Frequency', fontsize=12)\n",
    "# plt.grid(True, alpha=0.5)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the histogram of PYOE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(test_data['predicted_passing_yards'], bins=30, edgecolor='black', alpha=0.7)\n",
    "# plt.title('Distribution of Predicted Pass Yards', fontsize=16)\n",
    "# plt.xlabel('Passing Yards', fontsize=12)\n",
    "# plt.ylabel('Frequency', fontsize=12)\n",
    "# plt.grid(True, alpha=0.5)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the histogram of PYOE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(test_data['passing_yards'], bins=30, edgecolor='black', alpha=0.7)\n",
    "# plt.title('Distribution of Pass Yards', fontsize=16)\n",
    "# plt.xlabel('Passing Yards', fontsize=12)\n",
    "# plt.ylabel('Frequency', fontsize=12)\n",
    "# plt.grid(True, alpha=0.5)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the histogram of predicted passing yards and true passing yards\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot histogram for true passing yards\n",
    "# plt.hist(test_data['passing_yards'], bins=30, alpha=0.5, label='True Passing Yards', color='blue')\n",
    "\n",
    "# # Plot histogram for predicted passing yards\n",
    "# plt.hist(test_data['predicted_passing_yards'], bins=30, alpha=0.5, label='Predicted Passing Yards', color='orange')\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('Passing Yards')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of True vs Predicted Passing Yards on 2024 Season, Bins = 25')\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below checks a qb's simulator prediction with a bootstrapped curve that is custom to that team's own passing variance this year. rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Visualize Kyler Murray's simulated passing yards\n",
    "# kyler_murray_simulations = qb_simulations['Daniel Jones']\n",
    "\n",
    "# # Example: Visualize Kyler Murray's simulated passing yards using KDE plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.kdeplot(kyler_murray_simulations, fill=True)\n",
    "\n",
    "# # Add titles and labels\n",
    "# plt.title(\"KDE of Simulated Passing Yards for Kyler Murray\", fontsize=14)\n",
    "# plt.xlabel(\"Passing Yards\", fontsize=12)\n",
    "# plt.ylabel(\"Density\", fontsize=12)\n",
    "\n",
    "# # Show the plot\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "* Figure out wtm is when there is a new qb/injury\n",
    "* Find a way to tone down overpredictions (seems to be a weird trend this season people passing for less yards)\n",
    "* Week 1 stuff for next season\n",
    "* Write predictions to some sort of database for front end use? (ask pals with better knowledge on usable coding skills)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
